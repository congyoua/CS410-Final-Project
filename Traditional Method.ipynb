{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport string\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-10-31T22:21:25.297451Z","iopub.execute_input":"2023-10-31T22:21:25.298009Z","iopub.status.idle":"2023-10-31T22:21:25.678223Z","shell.execute_reply.started":"2023-10-31T22:21:25.297944Z","shell.execute_reply":"2023-10-31T22:21:25.677163Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/tweetdata/labeled_data.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"tweets = pd.read_csv(\"../input/tweetdata/labeled_data.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-10-31T22:21:25.679934Z","iopub.execute_input":"2023-10-31T22:21:25.680984Z","iopub.status.idle":"2023-10-31T22:21:25.765108Z","shell.execute_reply.started":"2023-10-31T22:21:25.680952Z","shell.execute_reply":"2023-10-31T22:21:25.764265Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"tweets.head","metadata":{"execution":{"iopub.status.busy":"2023-10-31T22:21:25.766649Z","iopub.execute_input":"2023-10-31T22:21:25.767105Z","iopub.status.idle":"2023-10-31T22:21:25.788258Z","shell.execute_reply.started":"2023-10-31T22:21:25.767079Z","shell.execute_reply":"2023-10-31T22:21:25.786712Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<bound method NDFrame.head of        Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n0               0      3            0                   0        3      2   \n1               1      3            0                   3        0      1   \n2               2      3            0                   3        0      1   \n3               3      3            0                   2        1      1   \n4               4      6            0                   6        0      1   \n...           ...    ...          ...                 ...      ...    ...   \n24778       25291      3            0                   2        1      1   \n24779       25292      3            0                   1        2      2   \n24780       25294      3            0                   3        0      1   \n24781       25295      6            0                   6        0      1   \n24782       25296      3            0                   0        3      2   \n\n                                                   tweet  \n0      !!! RT @mayasolovely: As a woman you shouldn't...  \n1      !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n2      !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n3      !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n4      !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  \n...                                                  ...  \n24778  you's a muthaf***in lie &#8220;@LifeAsKing: @2...  \n24779  you've gone and broke the wrong heart baby, an...  \n24780  young buck wanna eat!!.. dat nigguh like I ain...  \n24781              youu got wild bitches tellin you lies  \n24782  ~~Ruffled | Ntac Eileen Dahlia - Beautiful col...  \n\n[24783 rows x 7 columns]>"},"metadata":{}}]},{"cell_type":"code","source":"text_data = tweets[\"tweet\"]\nhatespeech_data = (tweets[tweets[\"class\"] == 0])[\"tweet\"]\noffensivelanguage_data = (tweets[tweets[\"class\"] == 1])[\"tweet\"]\nneither_data = (tweets[tweets[\"class\"] == 2])[\"tweet\"]\n\nclasses = [hatespeech_data, offensivelanguage_data, neither_data]\nnames = [\"hate speech\", \"offensive language\", \"neither\"]\n\n#Majority have been marked offensive language, followed by neither (less than a quarter), and hatespeech\nfor i in range(len(classes)):\n    print(names[i], len(classes[i]))","metadata":{"execution":{"iopub.status.busy":"2023-10-31T23:28:38.445344Z","iopub.execute_input":"2023-10-31T23:28:38.445815Z","iopub.status.idle":"2023-10-31T23:28:38.460235Z","shell.execute_reply.started":"2023-10-31T23:28:38.445781Z","shell.execute_reply":"2023-10-31T23:28:38.459090Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"hate speech 1430\noffensive language 19190\nneither 4163\n","output_type":"stream"}]},{"cell_type":"code","source":"top20s = []\ni = 0\nfor dataset in classes:\n    text = \"\"\n    for line in dataset:\n        text += line + \" \"\n    # print(text)\n    def checktoinclude(word):\n        for c in word:\n            if c in string.punctuation or c in \"0123456789\":\n                return False\n        return True\n\n    vocabulary = {}\n    vocab = [word.lower() for word in text.split() if (word not in string.punctuation and checktoinclude(word))]\n    for word in vocab:\n        if word in vocabulary.keys():\n            vocabulary[word]+= 1\n        else:\n            vocabulary[word] = 1\n    sorted_vocab = (sorted(((value,key) for (key,value) in vocabulary.items()), reverse=True))\n\n    # Remove stop words\n    stop_word_list = [\"get\", \"got\", \"like\", \"all\", \"just\", \"what\", \"these\", \"the\", \"you\", \"my\", \"me\", \"your\", \n                      \"if\", \"u\", \"ur\", \"do\", \"we\", \"a\", \"to\", \"how\", \"know\", \"knew\", \n                      \"of\", \"in\", \"and\", \"or\", \"on\", \"for\", \"this\", \"that\", \"go\", \"want\", \"why\",\n                      \"with\", \"as\", \"at\", \"its\", \"by\", \"is\", \"an\", \"has\", \"it\", \"i\",\n                      \"was\", \"are\", \"be\", \"but\", \"us\", \"not\", \"they\", \"then\", \"than\", \"were\",\n                      \"said\", \"from\", \"his\", \"after\", \"will\", \"have\", \"their\", \"over\",\n                      \"more\", \"he\", \"she\", \"up\", \"into\", \"out\", \"who\", \"when\", \"been\",\"had\", \n                      \"about\", \"which\", \"could\", \"can\", \"some\", \"so\", \"here\", \"there\", \"him\", \"her\", \"them\", \"yes\", \"no\"]\n    # print(sorted_vocab[:200])\n    # print([v for (k,v) in sorted_vocab])\n    new_vocab = [v for (k,v) in sorted_vocab if v not in stop_word_list]\n    # new_vocab = [s for s in new_vocab if s not in stop_word_list]\n    top20 = new_vocab[:20]\n    print(names[i], ':\\nTop 20 most frequent words: ', top20, '\\n')\n    for wd in top20:\n        print(wd, ':', vocabulary[wd])\n    print('--------------------------------------------\\n')\n    top20s.append(top20)\n    i+= 1","metadata":{"execution":{"iopub.status.busy":"2023-10-31T23:21:37.683452Z","iopub.execute_input":"2023-10-31T23:21:37.683817Z","iopub.status.idle":"2023-10-31T23:21:38.355068Z","shell.execute_reply.started":"2023-10-31T23:21:37.683790Z","shell.execute_reply":"2023-10-31T23:21:38.353904Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"hate speech :\nTop 20 most frequent words:  ['rt', 'bitch', 'faggot', 'ass', 'white', 'fuck', 'nigga', 'fucking', 'nigger', 'trash', 'niggas', 'hate', 'fag', 'bitches', 'shit', 'hoes', 'people', 'lol', 'pussy', 'faggots'] \n\nrt : 322\nbitch : 171\nfaggot : 149\nass : 128\nwhite : 123\nfuck : 115\nnigga : 114\nfucking : 93\nnigger : 83\ntrash : 71\nniggas : 67\nhate : 57\nfag : 57\nbitches : 54\nshit : 51\nhoes : 45\npeople : 42\nlol : 40\npussy : 38\nfaggots : 38\n--------------------------------------------\n\noffensive language :\nTop 20 most frequent words:  ['bitch', 'rt', 'bitches', 'hoes', 'pussy', 'hoe', 'ass', 'fuck', 'shit', 'nigga', 'lol', 'niggas', 'love', 'yo', 'fucking', 'one', 'bad', 'ya', 'im', 'good'] \n\nbitch : 6568\nrt : 5936\nbitches : 2623\nhoes : 1922\npussy : 1687\nhoe : 1425\nass : 1342\nfuck : 1196\nshit : 993\nnigga : 933\nlol : 769\nniggas : 638\nlove : 556\nyo : 539\nfucking : 524\none : 491\nbad : 472\nya : 429\nim : 388\ngood : 381\n--------------------------------------------\n\nneither :\nTop 20 most frequent words:  ['rt', 'trash', 'bird', 'charlie', 'yellow', 'birds', 'one', 'yankees', 'lol', 'colored', 'ghetto', 'now', 'new', 'monkey', 'make', 'love', 'would', 'good', 'see', 'off'] \n\nrt : 1309\ntrash : 524\nbird : 234\ncharlie : 233\nyellow : 179\nbirds : 122\none : 115\nyankees : 113\nlol : 110\ncolored : 104\nghetto : 91\nnow : 90\nnew : 86\nmonkey : 86\nmake : 82\nlove : 81\nwould : 80\ngood : 78\nsee : 75\noff : 74\n--------------------------------------------\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Check commonalities of most frequent words\n\nfor i in range(3):\n    for j in range(i+1, 3):\n            print(\"Common words in top20 between\", names[i], 'and', names[j], ':')\n            print(set(top20s[i])&set(top20s[j]), ', ', len(set(top20s[i])&set(top20s[j])), 'words\\n')","metadata":{"execution":{"iopub.status.busy":"2023-10-31T23:21:38.356706Z","iopub.execute_input":"2023-10-31T23:21:38.357111Z","iopub.status.idle":"2023-10-31T23:21:38.364560Z","shell.execute_reply.started":"2023-10-31T23:21:38.357070Z","shell.execute_reply":"2023-10-31T23:21:38.363384Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Common words in top20 between hate speech and offensive language :\n{'niggas', 'nigga', 'shit', 'bitch', 'rt', 'fucking', 'ass', 'lol', 'pussy', 'bitches', 'fuck', 'hoes'} ,  12 words\n\nCommon words in top20 between hate speech and neither :\n{'trash', 'lol', 'rt'} ,  3 words\n\nCommon words in top20 between offensive language and neither :\n{'good', 'rt', 'one', 'love', 'lol'} ,  5 words\n\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}